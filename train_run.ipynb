{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd3db8a",
   "metadata": {},
   "source": [
    "# Train Transformer (3-epoch run with checkpoints every 3 epochs)\n",
    "This notebook runs `train_main.py` with the requested config. Checkpoints are saved every 3 epochs and `best_model.pth` is overwritten at each save."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57caf3c4",
   "metadata": {},
   "source": [
    "## Download data and checkpoint from shared Drive\n",
    "Use the shared folder (data.zip + best_model.pth) to populate `data/processed/` and `training/checkpoints/` before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, subprocess, sys\n",
    "\n",
    "try:\n",
    "    import gdown  \n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "\n",
    "folder_id = \"1b2Wn_I3m2-2WBPI3H1TtDiR0URazIOsg\"\n",
    "workdir = pathlib.Path('.')\n",
    "\n",
    "data_dir = workdir / 'data' / 'processed'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_dir = workdir / 'training' / 'checkpoints'\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "download_dir = workdir / 'downloads'\n",
    "download_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print('Downloading folder from Drive...')\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable, '-m', 'gdown', '--folder', '--id', folder_id, '-O', str(download_dir)\n",
    "])\n",
    "\n",
    "zip_path = download_dir / 'data.zip'\n",
    "if zip_path.exists():\n",
    "    subprocess.check_call(['unzip', '-o', str(zip_path), '-d', str(data_dir)])\n",
    "    print('Unzipped data.zip into data/processed')\n",
    "else:\n",
    "    print('data.zip not found in downloaded folder; please check the shared Drive contents')\n",
    "\n",
    "# load checkpoint\n",
    "best_ckpt = download_dir / 'best_model.pth'\n",
    "if best_ckpt.exists():\n",
    "    target_ckpt = ckpt_dir / 'best_model.pth'\n",
    "    target_ckpt.write_bytes(best_ckpt.read_bytes())\n",
    "    print('best_model.pth copied to training/checkpoints')\n",
    "else:\n",
    "    print('best_model.pth not found in downloaded folder; continuing without it')\n",
    "\n",
    "print('Done downloading assets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe70326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "\n",
    "root = pathlib.Path('.')\n",
    "print('Current working dir:', root.resolve())\n",
    "\n",
    "source_path = pathlib.Path('data/processed/train_source_ids.npy')\n",
    "target_path = pathlib.Path('data/processed/train_target_ids.npy')\n",
    "print('Source exists:', source_path.exists())\n",
    "print('Target exists:', target_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = 0\n",
    "source_ids = 'data/processed/train_source_ids.npy'\n",
    "target_ids = 'data/processed/train_target_ids.npy'\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "d_model = 256\n",
    "num_encoder_layers = 4\n",
    "num_decoder_layers = 4\n",
    "d_ff = 1024\n",
    "num_heads = 8\n",
    "\n",
    "print('Config loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, textwrap, shlex\n",
    "\n",
    "cmd = f\"python train_main.py \\\\\\n  --pad_token_id {pad_token_id} \\\\\\n  --source_ids {source_ids} \\\\\\n  --target_ids {target_ids} \\\\\\n  --batch_size {batch_size} \\\\\\n  --epochs {epochs} \\\\\\n  --d_model {d_model} \\\\\\n  --num_encoder_layers {num_encoder_layers} \\\\\\n  --num_decoder_layers {num_decoder_layers} \\\\\\n  --d_ff {d_ff} \\\\\\n  --num_heads {num_heads}\"\n",
    "\n",
    "print('Running command:\\n', cmd)\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True)\n",
    "process.wait()\n",
    "print('Exit code:', process.returncode)\n",
    "\n",
    "import pathlib\n",
    "ckpt_dir = pathlib.Path('training/checkpoints')\n",
    "if ckpt_dir.exists():\n",
    "    print('Checkpoints:')\n",
    "    for p in sorted(ckpt_dir.glob('*.pth')):\n",
    "        print(' -', p)\n",
    "else:\n",
    "    print('No checkpoints directory found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c87e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, json\n",
    "metrics_path = pathlib.Path('training/metrics.json')\n",
    "if metrics_path.exists():\n",
    "    data = json.loads(metrics_path.read_text())\n",
    "    print('Last metrics entry:' if data else 'Metrics file empty')\n",
    "    if data:\n",
    "        print(data[-1])\n",
    "else:\n",
    "    print('metrics.json not found')\n",
    "\n",
    "best_model = pathlib.Path('training/checkpoints/best_model.pth')\n",
    "print('Best model exists:', best_model.exists())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
