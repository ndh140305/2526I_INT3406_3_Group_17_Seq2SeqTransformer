{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54341d4",
   "metadata": {},
   "source": [
    "## Clone repository and setup environment\n",
    "Clone the project from GitHub and navigate to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if not os.path.exists('/content/nlp_pj'):\n",
    "    print('Cloning repository...')\n",
    "    subprocess.check_call([\n",
    "        'git', 'clone', \n",
    "        'https://github.com/ndh140305/2526I_INT3406_3_Group_17_Seq2SeqTransformer',\n",
    "        '/content/nlp_pj'\n",
    "    ])\n",
    "    print('Repository cloned.')\n",
    "else:\n",
    "    print('Repository already exists.')\n",
    "\n",
    "os.chdir('/content/nlp_pj')\n",
    "print('Current directory:', os.getcwd())\n",
    "\n",
    "print('Installing dependencies...')\n",
    "subprocess.check_call(['pip', 'install', '-q', '-r', 'requirements.txt'])\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd3db8a",
   "metadata": {},
   "source": [
    "# Train Transformer (3-epoch run with checkpoints every 3 epochs)\n",
    "This notebook runs `train_main.py` with the requested config. Checkpoints are saved every 3 epochs and `best_model.pth` is overwritten at each save."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57caf3c4",
   "metadata": {},
   "source": [
    "## Download data and checkpoint from shared Drive\n",
    "Use the shared folder (data.zip + best_model.pth) to populate `data/processed/` and `training/checkpoints/` before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, subprocess, sys\n",
    "\n",
    "try:\n",
    "    import gdown  \n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "\n",
    "folder_id = \"1b2Wn_I3m2-2WBPI3H1TtDiR0URazIOsg\"\n",
    "workdir = pathlib.Path('.')\n",
    "\n",
    "data_dir = workdir / 'data' / 'processed'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_dir = workdir / 'training' / 'checkpoints'\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "download_dir = workdir / 'downloads'\n",
    "download_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print('Downloading folder from Drive...')\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable, '-m', 'gdown', '--folder', '--id', folder_id, '-O', str(download_dir)\n",
    "])\n",
    "\n",
    "zip_path = download_dir / 'data.zip'\n",
    "if zip_path.exists():\n",
    "    subprocess.check_call(['unzip', '-o', str(zip_path), '-d', str(data_dir)])\n",
    "    print('Unzipped data.zip into data/processed')\n",
    "else:\n",
    "    print('data.zip not found in downloaded folder; please check the shared Drive contents')\n",
    "\n",
    "# load checkpoint\n",
    "best_ckpt = download_dir / 'best_model.pth'\n",
    "if best_ckpt.exists():\n",
    "    target_ckpt = ckpt_dir / 'best_model.pth'\n",
    "    target_ckpt.write_bytes(best_ckpt.read_bytes())\n",
    "    print('best_model.pth copied to training/checkpoints')\n",
    "else:\n",
    "    print('best_model.pth not found in downloaded folder; continuing without it')\n",
    "\n",
    "print('Done downloading assets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe70326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "\n",
    "root = pathlib.Path('.')\n",
    "print('Current working dir:', root.resolve())\n",
    "\n",
    "source_path = pathlib.Path('data/processed/train_source_ids.npy')\n",
    "target_path = pathlib.Path('data/processed/train_target_ids.npy')\n",
    "print('Source exists:', source_path.exists())\n",
    "print('Target exists:', target_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6744f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "root = Path('.')\n",
    "expected_src = root / 'data' / 'processed' / 'train_source_ids.npy'\n",
    "expected_tgt = root / 'data' / 'processed' / 'train_target_ids.npy'\n",
    "\n",
    "if not expected_src.exists() or not expected_tgt.exists():\n",
    "    print('Attempting to locate missing data files and copy into data/processed...')\n",
    "    search_roots = [root / 'downloads', root / 'data']\n",
    "\n",
    "    def find_one(name):\n",
    "        for base in search_roots:\n",
    "            if base.exists():\n",
    "                matches = list(base.rglob(name))\n",
    "                if matches:\n",
    "                    return matches[0]\n",
    "        return None\n",
    "\n",
    "    src_found = expected_src if expected_src.exists() else find_one('train_source_ids.npy')\n",
    "    tgt_found = expected_tgt if expected_tgt.exists() else find_one('train_target_ids.npy')\n",
    "\n",
    "    (root / 'data' / 'processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if src_found and not expected_src.exists():\n",
    "        shutil.copy(src_found, expected_src)\n",
    "        print('Copied source from', src_found, '->', expected_src)\n",
    "    if tgt_found and not expected_tgt.exists():\n",
    "        shutil.copy(tgt_found, expected_tgt)\n",
    "        print('Copied target from', tgt_found, '->', expected_tgt)\n",
    "\n",
    "print('Source exists:', expected_src.exists())\n",
    "print('Target exists:', expected_tgt.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = 0\n",
    "source_ids = 'data/processed/train_source_ids.npy'\n",
    "target_ids = 'data/processed/train_target_ids.npy'\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "d_model = 256\n",
    "num_encoder_layers = 4\n",
    "num_decoder_layers = 4\n",
    "d_ff = 1024\n",
    "num_heads = 8\n",
    "\n",
    "print('Config loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, textwrap, shlex\n",
    "\n",
    "cmd = f\"python train_main.py \\\\\\n  --pad_token_id {pad_token_id} \\\\\\n  --source_ids {source_ids} \\\\\\n  --target_ids {target_ids} \\\\\\n  --batch_size {batch_size} \\\\\\n  --epochs {epochs} \\\\\\n  --d_model {d_model} \\\\\\n  --num_encoder_layers {num_encoder_layers} \\\\\\n  --num_decoder_layers {num_decoder_layers} \\\\\\n  --d_ff {d_ff} \\\\\\n  --num_heads {num_heads}\"\n",
    "\n",
    "print('Running command:\\n', cmd)\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "print('\\n--- STDOUT ---')\n",
    "print(stdout)\n",
    "if stderr:\n",
    "    print('\\n--- STDERR ---')\n",
    "    print(stderr)\n",
    "\n",
    "print('\\nExit code:', process.returncode)\n",
    "\n",
    "import pathlib\n",
    "ckpt_dir = pathlib.Path('training/checkpoints')\n",
    "if ckpt_dir.exists():\n",
    "    print('Checkpoints:')\n",
    "    for p in sorted(ckpt_dir.glob('*.pth')):\n",
    "        print(' -', p)\n",
    "else:\n",
    "    print('No checkpoints directory found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c87e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, json\n",
    "metrics_path = pathlib.Path('training/metrics.json')\n",
    "if metrics_path.exists():\n",
    "    data = json.loads(metrics_path.read_text())\n",
    "    print('Last metrics entry:' if data else 'Metrics file empty')\n",
    "    if data:\n",
    "        print(data[-1])\n",
    "else:\n",
    "    print('metrics.json not found')\n",
    "\n",
    "best_model = pathlib.Path('training/checkpoints/best_model.pth')\n",
    "print('Best model exists:', best_model.exists())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
